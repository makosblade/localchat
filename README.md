# LocalChat

## Executive Summary

LocalChat is a self-hosted web application that allows users to chat with AI models hosted at user-configured URLs. It provides a ChatGPT-like interface for interacting with any compatible AI model API, giving users full control over which models they use and where those models are hosted. LocalChat is perfect for developers, privacy-conscious users, and anyone who wants to interact with locally hosted or custom AI models through a familiar chat interface.

Key Features:
- **Profile Management**: Create, edit, and delete profiles with customizable API URLs, model names, and token sizes
- **Flexible API Integration**: Connect to any compatible API endpoint, including local models via Ollama
- **Chat Interface**: Modern UI with message history, Markdown rendering, and syntax highlighting
- **Streaming Responses**: Real-time streaming of AI responses with the ability to stop generation
- **Persistent History**: All conversations are saved and can be accessed later
- **Keyboard Shortcuts**: Efficient navigation and control with keyboard shortcuts

## Features

### Profile Management
Create and manage profiles for different AI models with customizable settings:
- API URL configuration
- Model name selection
- Token size adjustment
- Automatic model discovery for Ollama

### Chat Interface
- Real-time Markdown rendering with syntax highlighting
- Streaming responses with stop capability
- Message history navigation
- Keyboard shortcuts for efficient interaction

### User Experience
- Immediate message display with optimistic updates
- Chat history sidebar for quick navigation between conversations
- Tooltips for all action buttons
- Keyboard shortcuts (H: toggle history, S: toggle streaming, R: refresh, ESC: close sidebar)

## Contributing
Contributions are welcome! Please feel free to submit a PR.
